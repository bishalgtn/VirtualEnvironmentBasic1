# Web-Crawler-for-Vulnerability-Scanning


## Project Description
The WebScanCrawler is a Python-based simple web crawler designed to scan websites for basic security vulnerabilities. This tool is helpful for identifying common issues, such as missing HTTP security headers, outdated software versions, and insecure forms, which could pose risks to web applications.

The crawler:

1. Starts at a user-provided URL.
2. Crawls all pages linked from the starting URL within the same domain.
3. Checks for:
    - Missing HTTP security headers (e.g., X-Content-Type-Options, Strict-Transport   Security).
    - Outdated software versions (detected from HTTP headers or page content).
    - Insecure forms (e.g., forms using method="GET" or missing action attributes).

## Steps to Run the Code
1. **Clone the repository** to your local machine:
   ```bash
   git clone https://github.com/YourUsername/Web-Crawler-for-Vulnerability-Scanning.git
   cd Web-Crawler-for-Vulnerability-Scanning
2. **Install Dependencies**:
   Run the following command to install the necessary dependencies:
   ```bash
   pip install requests beautifulsoup4

3. **Run the Script:** 
   ```bash
   python web.crawlle.code.py

4. Sample Input and Output:
   
   **Enter the URL to scan:**
   ```markdown
   https://gtn.com.np
## **Here is the test file of GTN website.**


<img src="https://github.com/BisalDangol/Web-Crawler-for-Vulnerability-Scanning/blob/main/Scanning%20reasult%20of%20GTN.png" alt="Web-Crawler-for-Vulnerability-Scanning-Image" >


## **Here is the test file of Techspire website.** Here, we found Vulnerability.

<img src="https://github.com/BisalDangol/Web-Crawler-for-Vulnerability-Scanning/blob/main/vernuval%20found%20sample.png" alt="Web-Crawler-for-Vulnerability-Scanning-Image" >



### Assumptions:

1. The website follows standard HTTP/HTTPS protocols and provides proper response headers.
2. The crawler is limited to crawling only within the same domain (i.e., it does not follow external links).
3. Forms and software versions are detectable from static HTML or HTTP response headers.

### Dynamic Content:

The crawler does not handle JavaScript-rendered pages. For such cases, integrating tools like selenium would be required.
Outdated Software Detection:
Outdated software is detected based on explicit version strings found in HTTP headers or page content (e.g., Apache/2.4.6).
It does not dynamically check for the latest versions from the internet.



##
